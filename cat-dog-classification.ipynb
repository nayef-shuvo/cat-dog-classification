{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import io\n",
    "\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "\n",
    "# gpu_options = tf.compat.v1.GPUOptions(per_process_gpu_memory_fraction=0.6)\n",
    "# sess = tf.compat.v1.Session(config=tf.compat.v1.ConfigProto(gpu_options=gpu_options))\n",
    "\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  try:\n",
    "    # Currently, memory growth needs to be the same across GPUs\n",
    "    for gpu in gpus:\n",
    "      tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    # Memory growth must be set before GPUs have been initialized\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DIR = '../Dataset/training_set/training_set/'\n",
    "TEST_DIR = '../Dataset/test_set/test_set/'\n",
    "\n",
    "items = ['cats', 'dogs']\n",
    "SIZE = (120, 120, )\n",
    "\n",
    "X_train = []\n",
    "X_test = []\n",
    "Y_train = []\n",
    "Y_test = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Reading Training Data\n",
    "'''\n",
    "cats = []\n",
    "dogs = []\n",
    "\n",
    "for e in items:\n",
    "    _dir = os.path.join(TRAIN_DIR, e)\n",
    "\n",
    "    for path in glob.glob(_dir + '/*.jpg'):\n",
    "        img = io.imread(path, as_gray= True)\n",
    "        img = cv2.resize(img, SIZE)\n",
    "        if e == 'cats':\n",
    "            cats.append(img)\n",
    "        else:\n",
    "            dogs.append(img)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cats = np.array(cats)\n",
    "dogs = np.array(dogs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cats = np.expand_dims(cats, axis= -1)\n",
    "dogs = np.expand_dims(dogs, axis= -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Data Augmentation\n",
    "'''\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "gen = ImageDataGenerator(\n",
    "    rotation_range= 45,\n",
    "    height_shift_range= .2,\n",
    "    width_shift_range= .2,\n",
    "    zoom_range= .2,\n",
    "    vertical_flip= True,\n",
    "    horizontal_flip= True,\n",
    "    fill_mode= 'reflect',\n",
    ")\n",
    "BATCH_LEN = int(1e4)\n",
    "i = 0\n",
    "\n",
    "for batch in gen.flow(cats):\n",
    "    for img in batch:\n",
    "        X_train.append(img)\n",
    "    i += 1\n",
    "    if i >= BATCH_LEN:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(len(cats)):\n",
    "    Y_train.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_LEN = int(1e4)\n",
    "i = 0\n",
    "\n",
    "for batch in gen.flow(dogs):\n",
    "    for img in batch:\n",
    "        X_train.append(img)\n",
    "        Y_train.append(1)\n",
    "    i += 1\n",
    "    if i >= BATCH_LEN:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.expand_dims(X_train, axis= -1)\n",
    "X_test = np.expand_dims(X_test, axis= -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Reading testing data\n",
    "'''\n",
    "for e in items:\n",
    "    _dir = os.path.join(TEST_DIR, e)\n",
    "\n",
    "    for path in glob.glob(_dir + '/*.jpg'):\n",
    "        img = io.imread(path, as_gray= True)\n",
    "        img = cv2.resize(img, SIZE)\n",
    "        X_test.append(img)\n",
    "        Y_test.append(items.index(e))\n",
    "        \n",
    "\n",
    "X_test = np.array(X_test)\n",
    "Y_test = np.array(Y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "X_train, Y_train = shuffle(X_train, Y_train)\n",
    "X_test, Y_test = shuffle(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape , X_train.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = tf.expand_dims(X_train, -1)\n",
    "X_test = tf.expand_dims(X_test, -1)\n",
    "Y_train = keras.utils.to_categorical(Y_train, 2)\n",
    "Y_test = keras.utils.to_categorical(Y_test, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Conv2D(32, (3, 3), strides= (1, 1), input_shape= X_train.shape[1:], activation= 'selu'),\n",
    "    keras.layers.MaxPool2D(pool_size= (3, 3)),\n",
    "\n",
    "    keras.layers.Conv2D(24, (3, 3), strides= (2, 2), activation= 'selu'),\n",
    "    keras.layers.MaxPool2D(pool_size= (2, 2)),\n",
    "\n",
    "    tf.keras.layers.GlobalMaxPool2D(),\n",
    "\n",
    "    keras.layers.Dense(16, activation= 'relu'),\n",
    "    keras.layers.Dense(8, activation= 'relu'),\n",
    "    keras.layers.Dense(2, activation= 'softmax')\n",
    "\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer= keras.optimizers.Adam(), loss= keras.losses.categorical_crossentropy, metrics=['accuracy'])\n",
    "model.fit(X_train, Y_train, batch_size= 32, epochs= 10, validation_data= (X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7f1afeb7b40703b3519efd202d022c2c5e05970aea316b769a23e72cba9991d9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
